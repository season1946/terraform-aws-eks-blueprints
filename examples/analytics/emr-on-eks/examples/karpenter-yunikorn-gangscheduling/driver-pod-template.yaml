apiVersion: v1
kind: Pod
metadata:
  name: ny-taxi-driver
  namespace: emr-data-team-a
  labels:
    applicationId: ny-taxi-yunikorn
    queue: root.test
  annotations:
    yunikorn.apache.org/schedulingPolicyParameters: "placeholderTimeoutSeconds=30 gangSchedulingStyle=Hard"
    yunikorn.apache.org/task-group-name: "spark-driver"
    # YuniKorn Gang Scheduling Configuration
    # minMember should match with driver and executor instances
    # minResource cpu and memory should match with driver and executor cpu and memory. This includes sidecar container resources.
    # Resource below should never be less than the actual resources defined for Driver and Executor with sidecar containers
    yunikorn.apache.org/task-groups: |-
      [{
          "name": "spark-driver",
          "minMember": 1,
          "minResource": {
            "cpu": "1200m",
            "memory": "15Gi"
          },
          "nodeSelector": {
            "NodeGroupType": "SparkMemoryOptimized"
          },
          "tolerations": [{"key" : "spark-memory-optimized", "operator": "Exists", "effect": "NoSchedule"}]
        },
        {
          "name": "spark-executor",
          "minMember": 20,
          "minResource": {
            "cpu": "1200m",
            "memory": "15Gi"
          },
          "nodeSelector": {
            "NodeGroupType": "SparkMemoryOptimized"
          },
          "tolerations": [{"key" : "spark-memory-optimized", "operator": "Exists", "effect": "NoSchedule"}]
      }]
spec:
  volumes:
    - name: spark-local-dir-1
      hostPath:
        path: /local1
        type: Directory
    - name: spark-local-dir-2
      hostPath:
        path: /local2
        type: Directory

  nodeSelector:
    "NodeGroupType": "SparkMemoryOptimized"
    "topology.kubernetes.io/zone": "us-west-2b"

  containers:
    - name: spark-kubernetes-driver # Don't change this name. EMR on EKS looking for this name
      volumeMounts:
        - name: spark-local-dir-1
          mountPath: /data1
          readOnly: false
        - name: spark-local-dir-2
          mountPath: /data2
          readOnly: false

  tolerations:
    - key: "spark-memory-optimized"
      operator: "Exists"
      effect: "NoSchedule"
